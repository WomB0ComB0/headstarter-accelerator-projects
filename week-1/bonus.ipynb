{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import warnings\n",
    "import statsmodels.api as sm\n",
    "from typing import List, Dict, Set, Tuple, Optional, Callable\n",
    "from collections import Counter, defaultdict\n",
    "from functools import cache\n",
    "import datetime\n",
    "from math import sqrt, pow\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('data/fraudTest.csv')\n",
    "df_train = pd.read_csv('data/fraudTrain.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.is_fraud.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utils\n",
    "def calculate_age(date: datetime) -> datetime:\n",
    "  birthdate = datetime.datetime.strptime(date, \"%Y-%m-%d\")\n",
    "  today = datetime.datetime.today()\n",
    "  age = today.year - birthdate.year - ((today.month, today.day) < (birthdate.month, birthdate.day))\n",
    "  return age\n",
    "\n",
    "euc: Callable[[float, float, float, float], float] = lambda x2, x1, y2, y1: sqrt(pow((x2 - x1), 2) + pow((y2 - y1), 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Cleaning\n",
    "\n",
    "df_test.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "df_test.drop_duplicates(inplace=True)\n",
    "df_test.dropna(inplace=True)\n",
    "\n",
    "# Feature Engineering\n",
    "df_test['age'] = df_test['dob'].apply(calculate_age)\n",
    "df_test.drop(['dob'], axis=1, inplace=True)\n",
    "df_test['name'] = df_test['first'] + ' ' + df_test['last']\n",
    "df_test.drop(['first', 'last'], axis=1, inplace=True)\n",
    "df_test.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(style='whitegrid')\n",
    "plt.figure(figsize=(12, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns = df_test.select_dtypes(include=['float64', 'int64']).columns\n",
    "correlation_matrix = df_test[numeric_columns].corr()\n",
    "\n",
    "df_test['trans_timestamp'] = pd.to_datetime(df_test['trans_date_trans_time']).astype(np.int64) // 10**9\n",
    "numeric_columns = df_test.select_dtypes(include=['float64', 'int64']).columns\n",
    "correlation_matrix = df_test[numeric_columns].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the matplotlib figure size\n",
    "plt.figure(figsize=(14, 12))\n",
    "\n",
    "# Customize the heatmap\n",
    "sns.heatmap(\n",
    "    correlation_matrix,            # Your correlation matrix data\n",
    "    annot=True,                    # Display correlation values\n",
    "    cmap=\"coolwarm\",               # Color scheme for the heatmap\n",
    "    fmt=\".2f\",                     # Format to show 2 decimal points\n",
    "    linewidths=0.5,                # Line width between cells for clarity\n",
    "    linecolor=\"black\",             # Line color to separate cells\n",
    "    square=True,                   # Make each cell square-shaped\n",
    "    cbar_kws={'shrink': 0.8}       # Shrink the color bar for better fit\n",
    ")\n",
    "\n",
    "# Title and label customization\n",
    "plt.title(\"Correlation Matrix Heatmap\", fontsize=18, weight='bold')\n",
    "plt.xticks(rotation=45, ha='right', fontsize=12)  # Rotate x-axis labels for better readability\n",
    "plt.yticks(rotation=0, fontsize=12)               # Y-axis labels for clarity\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the plot size and style\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Create the count plot\n",
    "ax = sns.countplot(x='category', hue='is_fraud', data=df_test, palette='coolwarm')\n",
    "\n",
    "# Add title and labels\n",
    "plt.title('Fraud by Transaction Category', fontsize=16, weight='bold')\n",
    "plt.xlabel('Transaction Category', fontsize=14)\n",
    "plt.ylabel('Count', fontsize=14)\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Annotate each bar with the count value\n",
    "for container in ax.containers:\n",
    "    ax.bar_label(container, fmt='%d', label_type='edge', fontsize=10, padding=3)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the figure size for better visibility\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Create the scatterplot\n",
    "sns.scatterplot(\n",
    "    x='long', \n",
    "    y='lat', \n",
    "    hue='is_fraud',                 # Color by 'is_fraud' feature\n",
    "    data=df_test, \n",
    "    palette=\"coolwarm\",             # Custom color palette for contrast\n",
    "    edgecolor=\"k\",                  # Black edge color for each point\n",
    "    alpha=0.6,                      # Adjust alpha for visibility of overlapping points\n",
    "    s=70                            # Adjust marker size for clarity\n",
    ")\n",
    "\n",
    "# Customize the plot with title and labels\n",
    "plt.title('Geographical Distribution of Fraud', fontsize=18, weight='bold')\n",
    "plt.xlabel('Longitude', fontsize=14)\n",
    "plt.ylabel('Latitude', fontsize=14)\n",
    "\n",
    "# Fine-tune legend\n",
    "plt.legend(title=\"Fraud Status\", title_fontsize='13', fontsize='11', loc='upper right')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_probability = df_test.groupby('state')['is_fraud'].mean().reset_index()\n",
    "fraud_probability.columns = ['State', 'Fraud Probability']\n",
    "\n",
    "# Convert fraud probability to percentage format for better readability\n",
    "fraud_probability['Fraud Probability'] *= 100  # Convert to percentage\n",
    "\n",
    "# Sort by fraud probability for a better visual order\n",
    "fraud_probability = fraud_probability.sort_values(by='Fraud Probability', ascending=False)\n",
    "\n",
    "# Set the plot size and style\n",
    "plt.figure(figsize=(14, 10))\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Create a horizontal bar plot\n",
    "sns.barplot(\n",
    "    x='Fraud Probability', \n",
    "    y='State', \n",
    "    data=fraud_probability,\n",
    "    palette=\"coolwarm\"\n",
    ")\n",
    "\n",
    "# Add title and labels\n",
    "plt.title('Fraud Probability by State', fontsize=16, weight='bold')\n",
    "plt.xlabel('Fraud Probability (%)', fontsize=14)\n",
    "plt.ylabel('State', fontsize=14)\n",
    "\n",
    "# Display the values on each bar\n",
    "for index, value in enumerate(fraud_probability['Fraud Probability']):\n",
    "    plt.text(value + 0.5, index, f\"{value:.2f}%\", va='center')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-to-many linear regression\n",
    "target: str = 'is_fraud'\n",
    "\n",
    "predictors: List[str] = [\n",
    "  'amt', 'city_pop', 'merch_lat', 'merch_long'\n",
    "]\n",
    "\n",
    "lr_x = df_test[predictors]\n",
    "lr_y = df_test[target]\n",
    "\n",
    "lr_X_constant = sm.add_constant(lr_x)\n",
    "lr_model = sm.OLS(lr_y, lr_X_constant).fit()\n",
    "\n",
    "lr_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original column names in the DataFrame\n",
    "target: str = 'is_fraud'  # Target variable indicating fraud status\n",
    "predictors: List[str] = ['amt', 'city_pop', 'merch_lat', 'merch_long']\n",
    "\n",
    "# Mapping for human-readable names\n",
    "column_name_mapping = {\n",
    "    'is_fraud': 'Fraud Status',            # Target variable\n",
    "    'amt': 'Transaction Amount',            # Amount of the transaction\n",
    "    'city_pop': 'City Population',          # Population of the city\n",
    "    'merch_lat': 'Merchant Latitude',       # Latitude of the merchant\n",
    "    'merch_long': 'Merchant Longitude'      # Longitude of the merchant\n",
    "}\n",
    "\n",
    "# Set style and plot size\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize=(15, 30))\n",
    "\n",
    "# Create a pairplot\n",
    "pairplot = sns.pairplot(\n",
    "    df_test[predictors + [target]], \n",
    "    hue=target,                     # Color by 'is_fraud' feature\n",
    "    palette=\"coolwarm\",            # Use a distinct color palette\n",
    "    diag_kind=\"kde\",               # KDE plot on the diagonal for smooth distributions\n",
    "    plot_kws={'alpha': 0.6}        # Add transparency for overlapping points\n",
    ")\n",
    "\n",
    "# Add a main title using the mapping for readability\n",
    "pairplot.fig.suptitle('Pairplot of Predictor Features by Fraud Status', fontsize=18, y=1.02)\n",
    "\n",
    "# Update x and y axis labels with human-readable names\n",
    "for ax in pairplot.axes.flatten():\n",
    "    ax.set_xlabel(column_name_mapping.get(ax.get_xlabel(), ax.get_xlabel()))\n",
    "    ax.set_ylabel(column_name_mapping.get(ax.get_ylabel(), ax.get_ylabel()))\n",
    "\n",
    "# Adjust layout for better readability\n",
    "pairplot.fig.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the Euclidean distance between the user's location and the merchant location (lat, long)\n",
    "df_test['distance'] = df_test.apply(lambda row: euc(\n",
    "    row['merch_lat'], \n",
    "    row['lat'], \n",
    "    row['merch_long'], \n",
    "    row['long']\n",
    "), axis=1)\n",
    "\n",
    "plt.figure(figsize=(20, 10))  # Increased size for better visibility\n",
    "\n",
    "sns.histplot(\n",
    "    data=df_test, \n",
    "    x='amt', \n",
    "    kde=True,\n",
    "    hue='is_fraud',\n",
    "    multiple=\"stack\",\n",
    "    bins=30,  # Adjust number of bins if necessary\n",
    "    alpha=0.7  # Slight transparency for overlapping areas\n",
    ")\n",
    "\n",
    "plt.title('Transaction Amount Distribution', fontsize=22)  # Larger title font size\n",
    "plt.xlabel('Amount ($)', fontsize=18)  # Larger x-axis label\n",
    "plt.ylabel('Count', fontsize=18)  # Larger y-axis label\n",
    "plt.xticks(fontsize=14)  # Larger x-axis ticks\n",
    "plt.yticks(fontsize=14)  # Larger y-axis ticks\n",
    "plt.legend(title='Fraud Status', fontsize=14, title_fontsize=16, loc='upper right')  # Legend font sizes\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(\n",
    "    data=df_test, \n",
    "    x='distance', \n",
    "    kde=True,\n",
    "    hue='is_fraud',\n",
    "    multiple=\"stack\"\n",
    ")\n",
    "plt.title('User-Merchant Distance Distribution')\n",
    "plt.xlabel('Distance')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nSummary Statistics:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nTransaction Amounts:\")  \n",
    "df_test.groupby('is_fraud')['amt'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nUser-Merchant Distances:\")\n",
    "df_test.groupby('is_fraud')['distance'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, calculate age and add it to df_train (similar to what you did for df_test)\n",
    "df_train.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "df_train.drop_duplicates(inplace=True)\n",
    "df_train.dropna(inplace=True)\n",
    "df_train['age'] = df_train['dob'].apply(calculate_age)\n",
    "df_train.drop(['dob'], axis=1, inplace=True)\n",
    "df_train['name'] = df_train['first'] + ' ' + df_train['last']\n",
    "df_train.drop(['first', 'last'], axis=1, inplace=True)\n",
    "\n",
    "# Calculate distance for df_train\n",
    "df_train['distance'] = df_train.apply(lambda row: euc(\n",
    "    row['merch_lat'], \n",
    "    row['lat'], \n",
    "    row['merch_long'], \n",
    "    row['long']\n",
    "), axis=1)\n",
    "\n",
    "# Convert timestamp for df_train\n",
    "df_train['trans_timestamp'] = pd.to_datetime(df_train['trans_date_trans_time']).astype(np.int64) // 10**9\n",
    "\n",
    "# Drop irrelevant columns\n",
    "columns_to_drop: List[str] = [\n",
    "    'trans_date_trans_time',  # Already converted to trans_timestamp\n",
    "    'cc_num',                 # Sensitive information\n",
    "    'merchant',              # Categorical, high cardinality\n",
    "    'street',               # Too specific location data\n",
    "    'city',                 # Already have city_pop\n",
    "    'state',                # Already have geographic info\n",
    "    'zip',                  # Already have geographic info\n",
    "    'lat',                  # Already calculated distance\n",
    "    'long',                 # Already calculated distance\n",
    "    'merch_lat',            # Already calculated distance\n",
    "    'merch_long',           # Already calculated distance\n",
    "    'trans_num',            # Transaction identifier\n",
    "    'unix_time',            # Already have trans_timestamp\n",
    "    'name',                 # Personal identifier\n",
    "]\n",
    "\n",
    "# Keep important features\n",
    "columns_to_keep: List[str] = [\n",
    "    'category',             # Transaction category\n",
    "    'amt',                  # Transaction amount\n",
    "    'gender',              # Demographic info\n",
    "    'city_pop',            # Population density\n",
    "    'job',                 # Demographic info\n",
    "    'is_fraud',            # Target variable\n",
    "    'age',                 # Demographic info\n",
    "    'trans_timestamp',     # Timing information\n",
    "    'distance'             # Distance between user and merchant\n",
    "]\n",
    "# Drop columns\n",
    "df_test = df_test.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Columns to drop from df_train:\")\n",
    "columns_to_drop_train = [col for col in df_train.columns if col not in df_test.columns]\n",
    "print(columns_to_drop_train)\n",
    "\n",
    "fraud_train_df = df_train.drop(columns=columns_to_drop_train)\n",
    "fraud_test_df = df_test.copy()\n",
    "\n",
    "print(\"\\nFinal columns in fraud_train_df:\", fraud_train_df.columns.tolist())\n",
    "print(\"\\nFinal columns in fraud_test_df:\", fraud_test_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the desired column order\n",
    "column_order = sorted([\n",
    "    'category',\n",
    "    'amt',\n",
    "    'gender',\n",
    "    'city_pop',\n",
    "    'job',\n",
    "    'is_fraud',\n",
    "    'age',\n",
    "    'trans_timestamp',\n",
    "    'distance'\n",
    "])\n",
    "\n",
    "# Reorder columns in both dataframes\n",
    "fraud_train_df = fraud_train_df[column_order]\n",
    "fraud_test_df = fraud_test_df[column_order]\n",
    "\n",
    "# Verify the results\n",
    "print(\"\\nFinal columns in fraud_train_df:\", fraud_train_df.columns.tolist())\n",
    "print(\"\\nFinal columns in fraud_test_df:\", fraud_test_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = fraud_train_df.select_dtypes(include=['object']).columns.tolist()\n",
    "label_encoders = {}\n",
    "\n",
    "for col in categorical_columns:\n",
    "  combined_values = pd.concat([fraud_train_df[col], fraud_test_df[col]])\n",
    "  \n",
    "  codes, uniques = pd.factorize(combined_values)\n",
    "  \n",
    "  fraud_train_df[col] = pd.Categorical(fraud_train_df[col], categories=uniques).codes\n",
    "  fraud_test_df[col] = pd.Categorical(fraud_test_df[col], categories=uniques).codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = fraud_train_df.drop('is_fraud', axis=1)\n",
    "y_train = fraud_train_df['is_fraud']\n",
    "\n",
    "X_test = fraud_test_df.drop('is_fraud', axis=1)\n",
    "y_test = fraud_test_df['is_fraud']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_train_imputed = imputer.fit_transform(X_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.combine import SMOTEENN, SMOTETomek\n",
    "\n",
    "# Basic SMOTE with optimized parameters\n",
    "smote = SMOTE(\n",
    "    sampling_strategy='auto',     # Automatically determine ratio to make classes balanced\n",
    "    random_state=42,\n",
    "    k_neighbors=5,               # Number of nearest neighbors to use\n",
    "    n_jobs=-1,                   # Use all available processors\n",
    ")\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_imputed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=500,\n",
    "    max_depth=15,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=2,\n",
    "    max_features='sqrt',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Get feature names (assuming X_train_resampled is a DataFrame)\n",
    "feature_names = X_train_resampled.columns if hasattr(X_train_resampled, 'columns') else [f'Feature {i}' for i in range(X_train_resampled.shape[1])]\n",
    "\n",
    "# Calculate feature importances\n",
    "importances = model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "  accuracy_score, \n",
    "  classification_report, \n",
    "  confusion_matrix,\n",
    "  roc_curve, \n",
    "  precision_recall_curve, \n",
    "  average_precision_score,\n",
    "  roc_auc_score, f1_score\n",
    ")\n",
    "from datetime import datetime\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = LogisticRegression(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model.fit(X_train_resampled, y_train_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_predictions = lr_model.predict(X_test_scaled)\n",
    "lr_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_accuracy = accuracy_score(y_test, lr_predictions)\n",
    "lr_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(\n",
    "    model: Any,\n",
    "    X_train: pd.DataFrame,\n",
    "    X_test: pd.DataFrame,\n",
    "    y_train: pd.Series,\n",
    "    y_test: pd.Series,\n",
    "    file_name: str\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Comprehensive model evaluation function that includes training, \n",
    "    prediction, various metrics, and visualizations.\n",
    "    \n",
    "    Args:\n",
    "        model: The machine learning model to evaluate\n",
    "        X_train: Training features\n",
    "        X_test: Test features\n",
    "        y_train: Training labels\n",
    "        y_test: Test labels\n",
    "        file_name: Name for saving the model\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary containing all evaluation metrics\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    predictions = model.predict(X_test)\n",
    "    try:\n",
    "        pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "        has_probability = True\n",
    "    except (AttributeError, NotImplementedError):\n",
    "        has_probability = False\n",
    "        pred_proba = None\n",
    "    \n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score(y_test, predictions),\n",
    "        'f1': f1_score(y_test, predictions),\n",
    "        'training_time': training_time\n",
    "    }\n",
    "    \n",
    "    if has_probability:\n",
    "        metrics['roc_auc'] = roc_auc_score(y_test, pred_proba)\n",
    "        metrics['average_precision'] = average_precision_score(y_test, pred_proba)\n",
    "    \n",
    "    print(f\"\\n{'-'*50}\")\n",
    "    print(f\"Evaluation Results for {model.__class__.__name__}\")\n",
    "    print(f\"{'-'*50}\")\n",
    "    print(f\"Accuracy: {metrics['accuracy']:.4f}\")\n",
    "    print(f\"F1 Score: {metrics['f1']:.4f}\")\n",
    "    if has_probability:\n",
    "        print(f\"ROC AUC: {metrics['roc_auc']:.4f}\")\n",
    "        print(f\"Average Precision: {metrics['average_precision']:.4f}\")\n",
    "    print(f\"Training Time: {training_time:.2f} seconds\")\n",
    "    \n",
    "    print(f\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, predictions))\n",
    "    \n",
    "    plt.figure(figsize=(20, 10))\n",
    "    \n",
    "    plt.subplot(2, 2, 1)\n",
    "    cm = confusion_matrix(y_test, predictions)\n",
    "    sns.heatmap(\n",
    "        cm,\n",
    "        annot=True,\n",
    "        fmt='d',\n",
    "        cmap='Blues',\n",
    "        xticklabels=['Not Fraud', 'Fraud'],\n",
    "        yticklabels=['Not Fraud', 'Fraud']\n",
    "    )\n",
    "    plt.title(f'Confusion Matrix - {model.__class__.__name__}')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    \n",
    "    if has_probability:\n",
    "        # 2. ROC Curve\n",
    "        plt.subplot(2, 2, 2)\n",
    "        fpr, tpr, _ = roc_curve(y_test, pred_proba)\n",
    "        plt.plot(fpr, tpr, label=f'ROC curve (AUC = {metrics[\"roc_auc\"]:.3f})')\n",
    "        plt.plot([0, 1], [0, 1], 'k--')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('ROC Curve')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        \n",
    "        # 3. Precision-Recall Curve\n",
    "        plt.subplot(2, 2, 3)\n",
    "        precision, recall, _ = precision_recall_curve(y_test, pred_proba)\n",
    "        plt.plot(recall, precision, label=f'PR curve (AP = {metrics[\"average_precision\"]:.3f})')\n",
    "        plt.xlabel('Recall')\n",
    "        plt.ylabel('Precision')\n",
    "        plt.title('Precision-Recall Curve')\n",
    "        plt.legend(loc=\"lower left\")\n",
    "        \n",
    "        # 4. Prediction Distribution\n",
    "        plt.subplot(2, 2, 4)\n",
    "        sns.kdeplot(data=pd.DataFrame({\n",
    "            'Probability': pred_proba,\n",
    "            'Class': y_test\n",
    "        }), x='Probability', hue='Class')\n",
    "        plt.title('Prediction Probability Distribution')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Save model with timestamp\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    save_path = f\"./out/bonus/{file_name}_{timestamp}.pkl\"\n",
    "    \n",
    "    try:\n",
    "        with open(save_path, \"wb\") as f:\n",
    "            pickle.dump(model, f)\n",
    "        print(f\"\\nModel saved successfully to: {save_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nError saving model: {str(e)}\")\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost with optimized parameters\n",
    "xgboost_model = xgb.XGBClassifier(\n",
    "    n_estimators=1000,          # More trees often yield better performance\n",
    "    learning_rate=0.01,         # Smaller learning rate for better generalization\n",
    "    max_depth=6,                # Control tree depth to prevent overfitting\n",
    "    min_child_weight=1,         # Minimum sum of instance weight needed in a child\n",
    "    gamma=0.1,                  # Minimum loss reduction for partition\n",
    "    subsample=0.8,              # Fraction of samples used for training trees\n",
    "    colsample_bytree=0.8,       # Fraction of features used for training trees\n",
    "    random_state=42\n",
    ")\n",
    "evaluate_model(xgboost_model, X_train_resampled, X_test_scaled, y_train_resampled, y_test, \"xgb_model\")\n",
    "\n",
    "# Random Forest with optimized parameters\n",
    "random_forest_model = RandomForestClassifier(\n",
    "    n_estimators=500,           # Number of trees\n",
    "    max_depth=15,               # Maximum depth of trees\n",
    "    min_samples_split=5,        # Minimum samples required to split\n",
    "    min_samples_leaf=2,         # Minimum samples required at leaf node\n",
    "    max_features='sqrt',        # Number of features to consider at each split\n",
    "    bootstrap=True,             # Use bootstrap samples\n",
    "    class_weight='balanced',    # Handle class imbalance\n",
    "    random_state=42\n",
    ")\n",
    "# evaluate_model(random_forest_model, X_train_resampled, X_test_scaled, y_train_resampled, y_test, \"rf_model\")\n",
    "\n",
    "# Decision Tree with optimized parameters\n",
    "decision_tree_model = DecisionTreeClassifier(\n",
    "    max_depth=8,                # Control tree depth\n",
    "    min_samples_split=10,       # Minimum samples required to split\n",
    "    min_samples_leaf=4,         # Minimum samples required at leaf node\n",
    "    max_features='sqrt',        # Number of features to consider\n",
    "    class_weight='balanced',    # Handle class imbalance\n",
    "    random_state=42\n",
    ")\n",
    "evaluate_model(decision_tree_model, X_train_resampled, X_test_scaled, y_train_resampled, y_test, \"dt_model\")\n",
    "\n",
    "# SVC with optimized parameters\n",
    "svc_model = SVC(\n",
    "    C=10.0,                     # Regularization parameter\n",
    "    kernel='rbf',               # Radial basis function kernel\n",
    "    gamma='scale',              # Kernel coefficient\n",
    "    probability=True,           # Enable probability estimates\n",
    "    class_weight='balanced',    # Handle class imbalance\n",
    "    random_state=42\n",
    ")\n",
    "# evaluate_model(svc_model, X_train_resampled, X_test_scaled, y_train_resampled, y_test, \"svc_model\")\n",
    "\n",
    "# Naive Bayes with optimized parameters\n",
    "# Note: GaussianNB has fewer parameters to tune\n",
    "naive_bayes_model = GaussianNB(\n",
    "    var_smoothing=1e-9          # Stability adjustment\n",
    ")\n",
    "# evaluate_model(naive_bayes_model, X_train_resampled, X_test_scaled, y_train_resampled, y_test, \"nb_model\")\n",
    "\n",
    "# KNN with optimized parameters\n",
    "knn_model = KNeighborsClassifier(\n",
    "    n_neighbors=5,              # Number of neighbors\n",
    "    weights='distance',         # Weight points by distance\n",
    "    algorithm='auto',           # Automatically choose best algorithm\n",
    "    leaf_size=30,              # Leaf size for tree algorithms\n",
    "    p=2,                       # Power parameter for Minkowski metric (2 = Euclidean)\n",
    "    metric='minkowski'         # Distance metric to use\n",
    ")\n",
    "# evaluate_model(knn_model, X_train_resampled, X_test_scaled, y_train_resampled, y_test, \"knn_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "def analyze_feature_importance(\n",
    "    model,\n",
    "    X_train: pd.DataFrame,\n",
    "    X_test: pd.DataFrame,\n",
    "    y_test: pd.Series,\n",
    "    n_top_features: int = 20\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Comprehensive feature importance analysis with multiple metrics and visualizations.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained model with feature_importances_ attribute\n",
    "        X_train: Training data\n",
    "        X_test: Test data\n",
    "        y_test: Test labels\n",
    "        n_top_features: Number of top features to display\n",
    "    \"\"\"\n",
    "    # Get feature importances from model\n",
    "    feature_importances = model.feature_importances_\n",
    "    feature_names = X_train.columns\n",
    "    \n",
    "    # Create base DataFrame\n",
    "    feature_importance_df = pd.DataFrame({\n",
    "        'Feature': feature_names,\n",
    "        'Importance': feature_importances\n",
    "    }).sort_values('Importance', ascending=False)\n",
    "    \n",
    "    # Calculate cumulative importance\n",
    "    feature_importance_df['Cumulative_Importance'] = np.cumsum(\n",
    "        feature_importance_df['Importance']\n",
    "    )\n",
    "    \n",
    "    # Calculate permutation importance\n",
    "    perm_importance = permutation_importance(\n",
    "        model, X_test, y_test,\n",
    "        n_repeats=10,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # Add permutation importance to DataFrame\n",
    "    feature_importance_df['Permutation_Importance'] = pd.Series(\n",
    "        perm_importance.importances_mean,\n",
    "        index=feature_importance_df.index\n",
    "    )\n",
    "    \n",
    "    # Calculate feature importance statistics\n",
    "    importance_stats = {\n",
    "        'n_important_features': sum(feature_importance_df['Importance'] > 0.01),\n",
    "        'top_features_90_percent': sum(feature_importance_df['Cumulative_Importance'] <= 0.9),\n",
    "        'correlation_matrix': calculate_feature_correlations(X_train, feature_importance_df)\n",
    "    }\n",
    "    \n",
    "    # Create visualizations\n",
    "    plt.figure(figsize=(20, 15))\n",
    "    \n",
    "    # 1. Bar plot of top feature importances\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plot_top_features(feature_importance_df, n_top_features, 'Feature Importance (MDI)')\n",
    "    \n",
    "    # 2. Bar plot of permutation importances\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plot_permutation_importance(feature_importance_df, n_top_features)\n",
    "    \n",
    "    # 3. Cumulative importance plot\n",
    "    plt.subplot(2, 2, 3)\n",
    "    plot_cumulative_importance(feature_importance_df)\n",
    "    \n",
    "    # 4. Feature correlation heatmap\n",
    "    plt.subplot(2, 2, 4)\n",
    "    plot_feature_correlations(importance_stats['correlation_matrix'], n_top_features)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print detailed analysis\n",
    "    print_feature_importance_analysis(feature_importance_df, importance_stats)\n",
    "    \n",
    "    return feature_importance_df, importance_stats\n",
    "\n",
    "def calculate_feature_correlations(X_train: pd.DataFrame, importance_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Calculate correlations between top important features.\"\"\"\n",
    "    top_features = importance_df['Feature'].head(10).tolist()\n",
    "    return X_train[top_features].corr()\n",
    "\n",
    "def plot_top_features(df: pd.DataFrame, n_features: int, title: str):\n",
    "    \"\"\"Plot top n important features.\"\"\"\n",
    "    sns.barplot(\n",
    "        data=df.head(n_features),\n",
    "        x='Importance',\n",
    "        y='Feature',\n",
    "        palette='viridis'\n",
    "    )\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Importance Score')\n",
    "    plt.ylabel('Features')\n",
    "\n",
    "def plot_permutation_importance(df: pd.DataFrame, n_features: int):\n",
    "    \"\"\"Plot permutation importance for top features.\"\"\"\n",
    "    sns.barplot(\n",
    "        data=df.head(n_features),\n",
    "        x='Permutation_Importance',\n",
    "        y='Feature',\n",
    "        palette='viridis'\n",
    "    )\n",
    "    plt.title('Permutation Importance')\n",
    "    plt.xlabel('Permutation Importance Score')\n",
    "    plt.ylabel('Features')\n",
    "\n",
    "def plot_cumulative_importance(df: pd.DataFrame):\n",
    "    \"\"\"Plot cumulative importance curve.\"\"\"\n",
    "    plt.plot(range(len(df)), df['Cumulative_Importance'], 'b-')\n",
    "    plt.hlines(y=0.9, xmin=0, xmax=len(df), color='r', linestyles='--')\n",
    "    plt.title('Cumulative Feature Importance')\n",
    "    plt.xlabel('Number of Features')\n",
    "    plt.ylabel('Cumulative Importance')\n",
    "\n",
    "def plot_feature_correlations(corr_matrix: pd.DataFrame, n_features: int):\n",
    "    \"\"\"Plot correlation heatmap for top features.\"\"\"\n",
    "    sns.heatmap(\n",
    "        corr_matrix,\n",
    "        annot=True,\n",
    "        cmap='coolwarm',\n",
    "        center=0,\n",
    "        fmt='.2f'\n",
    "    )\n",
    "    plt.title('Feature Correlations')\n",
    "\n",
    "def print_feature_importance_analysis(df: pd.DataFrame, stats: dict):\n",
    "    \"\"\"Print detailed analysis of feature importance.\"\"\"\n",
    "    print(\"\\nFeature Importance Analysis\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    print(f\"\\nTop 10 Most Important Features:\")\n",
    "    print(df[['Feature', 'Importance', 'Permutation_Importance']].head(10))\n",
    "    \n",
    "    print(f\"\\nFeature Importance Statistics:\")\n",
    "    print(f\"- Number of important features (>1% importance): {stats['n_important_features']}\")\n",
    "    print(f\"- Features needed for 90% cumulative importance: {stats['top_features_90_percent']}\")\n",
    "    \n",
    "    print(\"\\nFeature Categories Distribution:\")\n",
    "    categorical_features = df[df['Feature'].str.contains('cat_', case=False)]\n",
    "    numerical_features = df[~df['Feature'].str.contains('cat_', case=False)]\n",
    "    \n",
    "    print(f\"- Categorical features in top 10: {sum(categorical_features['Feature'].head(10).count())}\")\n",
    "    print(f\"- Numerical features in top 10: {sum(numerical_features['Feature'].head(10).count())}\")\n",
    "\n",
    "feature_importance_df, importance_stats = analyze_feature_importance(\n",
    "    xgboost_model,\n",
    "    X_train,\n",
    "    X_test_scaled,\n",
    "    y_test\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "feature_importance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='Importance', y='Feature', data=feature_importance_df)\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Feature Importances')\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['age_group'] = pd.cut(fraud_train_df['age'], bins=[0, 18, 25, 35, 45, 55, 65, 100], labels=['0-18', '19-25', '26-35', '36-45', '46-55', '56-65', '65+'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['hour'] = pd.to_datetime(fraud_train_df['trans_timestamp'], unit='s').dt.hour\n",
    "X_train['day_of_week'] = pd.to_datetime(fraud_train_df['trans_timestamp'], unit='s').dt.dayofweek\n",
    "X_train['is_weekend'] = X_train['day_of_week'].isin([5, 6]).astype(int)\n",
    "X_train['is_night'] = X_train['hour'].between(22, 6).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['amount_bin'] = pd.qcut(fraud_train_df['amt'], q=5, labels=['very_low', 'low', 'medium', 'high', 'very_high'])\n",
    "X_train['is_large_transaction'] = (fraud_train_df['amt'] > fraud_train_df['amt'].quantile(0.95)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['population_density_category'] = pd.qcut(\n",
    "    X_train['city_pop'], \n",
    "    q=5, \n",
    "    labels=['rural', 'suburban', 'urban', 'metropolitan', 'dense_metropolitan']\n",
    ")\n",
    "X_train['is_remote_transaction'] = (X_train['distance'] > X_train['distance'].quantile(0.75)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.get_dummies(X_train, drop_first=True)\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model_improved = xgb.XGBClassifier(random_state=42)\n",
    "evaluate_model(xgb_model_improved, X_train, X_test, y_train, y_test, \"xgb_model_improved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "xgb_model_improved = xgb.XGBClassifier(random_state=42)\n",
    "evaluate_model(xgb_model_improved, X_train_resampled, X_test, y_train_resampled, y_test, \"xgb_model_smote\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint, uniform\n",
    "\n",
    "xgb_params = {\n",
    "    'n_estimators': randint(100, 1000),\n",
    "    'max_depth': randint(3, 10),\n",
    "    'learning_rate': uniform(0.01, 0.3),\n",
    "    'subsample': uniform(0.6, 0.4),\n",
    "    'colsample_bytree': uniform(0.6, 0.4),\n",
    "    'min_child_weight': randint(1, 7),\n",
    "    'gamma': uniform(0, 0.5)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_base = xgb.XGBClassifier(random_state=42, n_jobs=-1)\n",
    "\n",
    "# Initialize RandomizedSearchCV\n",
    "xgb_random = RandomizedSearchCV(\n",
    "    estimator=xgb_base,\n",
    "    param_distributions=xgb_params,\n",
    "    n_iter=25,  # Number of parameter settings sampled\n",
    "    cv=3,       # Number of folds\n",
    "    verbose=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,  # Use all CPU cores\n",
    "    scoring='f1'  # Optimize for F1 score\n",
    ")\n",
    "\n",
    "# Fit the model with SMOTE-resampled data\n",
    "xgb_random.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Get best model and parameters\n",
    "best_xgb = xgb_random.best_estimator_\n",
    "print(\"Best parameters:\", xgb_random.best_params_)\n",
    "\n",
    "# Evaluate the optimized model\n",
    "evaluate_model(best_xgb, X_train_resampled, X_test, y_train_resampled, y_test, \"xgb_optimized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_model = VotingClassifier(estimators=[\n",
    "    ('xgb', best_xgb),\n",
    "    ('rf', RandomForestClassifier(\n",
    "        n_estimators=500,\n",
    "        max_depth=8,\n",
    "        min_samples_split=5,\n",
    "        min_samples_leaf=2,\n",
    "        class_weight='balanced',\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )),\n",
    "    ('dt', DecisionTreeClassifier(\n",
    "        max_depth=6,\n",
    "        min_samples_split=10,\n",
    "        min_samples_leaf=4,\n",
    "        class_weight='balanced',\n",
    "        random_state=42\n",
    "    ))\n",
    "], voting='soft', weights=[2, 1, 1])\n",
    "\n",
    "evaluate_model(voting_model, X_train_resampled, X_test, y_train_resampled, y_test, \"voting_model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
